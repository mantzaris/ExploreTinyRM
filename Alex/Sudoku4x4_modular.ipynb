{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c747086a",
   "metadata": {},
   "source": [
    "# Modular TRM Training for Sudoku 4x4\n",
    "\n",
    "This notebook demonstrates a modular approach to training and evaluating a TRM neural network on 4x4 Sudoku puzzles using PyTorch. The code is organized for easy adaptation to other games and datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba74970",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Set Up Environment\n",
    "Import all required libraries, set random seeds, and configure device (CPU/GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd44433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os, math, random\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Any, List\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "sys.path.append(os.path.join(\"..\", \"src\"))\n",
    "from exploretinyrm.trm import TRM, TRMConfig\n",
    "def set_seed(seed: int = 123):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(123)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25a3125",
   "metadata": {},
   "source": [
    "## 2. AMP and EMA Utilities\n",
    "Define automatic mixed precision (AMP) and exponential moving average (EMA) utility functions and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f46b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torch.amp import autocast as _autocast, GradScaler as _GradScaler\n",
    "    _USE_TORCH_AMP = True\n",
    "except ImportError:\n",
    "    from torch.cuda.amp import autocast as _autocast, GradScaler as _GradScaler\n",
    "    _USE_TORCH_AMP = False\n",
    "\n",
    "def make_grad_scaler(is_cuda: bool):\n",
    "    if _USE_TORCH_AMP:\n",
    "        try:\n",
    "            return _GradScaler(\"cuda\", enabled=is_cuda)\n",
    "        except TypeError:\n",
    "            return _GradScaler(enabled=is_cuda)\n",
    "    else:\n",
    "        return _GradScaler(enabled=is_cuda)\n",
    "\n",
    "def amp_autocast(is_cuda: bool, use_amp: bool):\n",
    "    if _USE_TORCH_AMP:\n",
    "        try:\n",
    "            return _autocast(device_type=\"cuda\", enabled=(is_cuda and use_amp))\n",
    "        except TypeError:\n",
    "            return _autocast(enabled=(is_cuda and use_amp))\n",
    "    else:\n",
    "        return _autocast(enabled=(is_cuda and use_amp))\n",
    "\n",
    "class EMA:\n",
    "    def __init__(self, model: torch.nn.Module, decay: float = 0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {\n",
    "            name: param.detach().clone()\n",
    "            for name, param in model.named_parameters()\n",
    "            if param.requires_grad\n",
    "        }\n",
    "\n",
    "    def update(self, model: torch.nn.Module) -> None:\n",
    "        d = self.decay\n",
    "        with torch.no_grad():\n",
    "            for name, param in model.named_parameters():\n",
    "                if not param.requires_grad:\n",
    "                    continue\n",
    "                self.shadow[name].mul_(d).add_(param.detach(), alpha=1.0 - d)\n",
    "\n",
    "    def copy_to(self, model: torch.nn.Module) -> None:\n",
    "        with torch.no_grad():\n",
    "            for name, param in model.named_parameters():\n",
    "                if name in self.shadow:\n",
    "                    param.copy_(self.shadow[name])\n",
    "\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def use_ema_weights(model: torch.nn.Module, ema: EMA):\n",
    "    backup = {\n",
    "        name: param.detach().clone()\n",
    "        for name, param in model.named_parameters()\n",
    "        if param.requires_grad\n",
    "    }\n",
    "    ema.copy_to(model)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        with torch.no_grad():\n",
    "            for name, param in model.named_parameters():\n",
    "                if name in backup:\n",
    "                    param.copy_(backup[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9fdcc4",
   "metadata": {},
   "source": [
    "## 3. Sudoku 4x4 Dataset Preparation\n",
    "Implement dataset generation, including solution permutation, puzzle masking, and PyTorch Dataset/DataLoader setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c29b4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameDataset(Dataset):\n",
    "    \"\"\"Base class for game datasets. Subclass and implement _generate_sample.\"\"\"\n",
    "    def __init__(self, n_samples: int, seed: int = 0):\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.samples = [self._generate_sample() for _ in range(n_samples)]\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx): return self.samples[idx]\n",
    "    def _generate_sample(self): raise NotImplementedError()\n",
    "\n",
    "# --- Sudoku4x4 Dataset ---\n",
    "SIDE = 4\n",
    "BASE = 2\n",
    "INPUT_PAD = 0               # 0 marks blank in the INPUT ONLY\n",
    "INPUT_TOKENS = SIDE + 1     # {0..4} for inputs\n",
    "OUTPUT_TOKENS = SIDE        # {0..3} for outputs (represents digits 1..4)\n",
    "\n",
    "BASE_SOLUTION = np.array([\n",
    "    [1, 2, 3, 4],\n",
    "    [3, 4, 1, 2],\n",
    "    [2, 1, 4, 3],\n",
    "    [4, 3, 2, 1],\n",
    "], dtype=np.int64)\n",
    "\n",
    "def permute_solution(board: np.ndarray, rng: np.random.Generator) -> np.ndarray:\n",
    "    b = BASE; s = SIDE\n",
    "    row_idx = []\n",
    "    bands = [list(range(g*b, (g+1)*b)) for g in range(b)]\n",
    "    for band in bands:\n",
    "        rng.shuffle(band); row_idx.extend(band)\n",
    "    board = board[row_idx, :]\n",
    "    col_idx = []\n",
    "    stacks = [list(range(g*b, (g+1)*b)) for g in range(b)]\n",
    "    for stack in stacks:\n",
    "        rng.shuffle(stack); col_idx.extend(stack)\n",
    "    board = board[:, col_idx]\n",
    "    band_order = list(range(b)); rng.shuffle(band_order)\n",
    "    row_idx = []\n",
    "    for g in band_order: row_idx.extend(list(range(g*b, (g+1)*b)))\n",
    "    board = board[row_idx, :]\n",
    "    stack_order = list(range(b)); rng.shuffle(stack_order)\n",
    "    col_idx = []\n",
    "    for g in stack_order: col_idx.extend(list(range(g*b, (g+1)*b)))\n",
    "    board = board[:, col_idx]\n",
    "    digits = np.arange(1, s+1); rng.shuffle(digits)\n",
    "    mapping = {i+1: digits[i] for i in range(s)}\n",
    "    return np.vectorize(lambda v: mapping[v])(board)\n",
    "\n",
    "def make_puzzle(solution: np.ndarray, p_blank: float, rng: np.random.Generator) -> np.ndarray:\n",
    "    mask = rng.random(solution.shape) < p_blank\n",
    "    puzzle = solution.copy()\n",
    "    puzzle[mask] = INPUT_PAD\n",
    "    return puzzle\n",
    "\n",
    "class Sudoku4x4(GameDataset):\n",
    "    def __init__(self, n_samples: int, p_blank: float = 0.5, seed: int = 0):\n",
    "        self.p_blank = p_blank\n",
    "        super().__init__(n_samples, seed)\n",
    "    def _generate_sample(self):\n",
    "        sol = permute_solution(BASE_SOLUTION, self.rng)\n",
    "        puz = make_puzzle(sol, p_blank=self.p_blank, rng=self.rng)\n",
    "        x_tokens = puz.reshape(-1).astype(np.int64)         # [16], values in {0..4}\n",
    "        y_digits = sol.reshape(-1).astype(np.int64)         # [16], values in {1..4}\n",
    "        y_tokens = (y_digits - 1)                           # map to {0..3} for CE\n",
    "        return torch.from_numpy(x_tokens), torch.from_numpy(y_tokens)\n",
    "\n",
    "def get_loaders(n_train=512, n_val=128, batch_size=16, p_blank=0.45, seed=123):\n",
    "    ds_tr = Sudoku4x4(n_train, p_blank=p_blank, seed=seed)\n",
    "    ds_va = Sudoku4x4(n_val,   p_blank=p_blank, seed=seed+1)\n",
    "    return (\n",
    "        DataLoader(ds_tr, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True),\n",
    "        DataLoader(ds_va, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    )\n",
    "\n",
    "train_loader, val_loader = get_loaders(\n",
    "    n_train=2048,\n",
    "    n_val=512,\n",
    "    batch_size=16,\n",
    "    p_blank=0.50,\n",
    "    seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f303691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Input Puzzle:\n",
      "[[2 4 0 3]\n",
      " [1 3 0 4]\n",
      " [0 2 3 1]\n",
      " [0 1 4 0]]\n",
      "Solution:\n",
      "[[2 4 1 3]\n",
      " [1 3 2 4]\n",
      " [4 2 3 1]\n",
      " [3 1 4 2]]\n",
      "\n",
      "Example 1:\n",
      "Input Puzzle:\n",
      "[[0 0 3 1]\n",
      " [3 1 2 0]\n",
      " [4 2 0 3]\n",
      " [1 0 4 0]]\n",
      "Solution:\n",
      "[[2 4 3 1]\n",
      " [3 1 2 4]\n",
      " [4 2 1 3]\n",
      " [1 3 4 2]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    x, y = train_loader.dataset[i]\n",
    "    x_board = x.numpy().reshape(SIDE, SIDE)\n",
    "    y_board = y.numpy().reshape(SIDE, SIDE) + 1\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Input Puzzle:\")\n",
    "    print(x_board)\n",
    "    print(\"Solution:\")\n",
    "    print(y_board)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d86f61",
   "metadata": {},
   "source": [
    "## 4. Model Configuration and Initialization\n",
    "Configure TRM model parameters, instantiate the model, optimizer, scaler, and EMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d47e6db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params (M): 0.397312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhopw\\miniconda3\\envs\\torch121\\Lib\\site-packages\\torch\\cuda\\__init__.py:235: UserWarning: \n",
      "NVIDIA GeForce RTX 5060 Ti with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90 sm_37 compute_37.\n",
      "If you want to use the NVIDIA GeForce RTX 5060 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "D_MODEL = 128\n",
    "SEQ_LEN = SIDE * SIDE\n",
    "N_SUP   = 16\n",
    "N       = 6\n",
    "T       = 3\n",
    "USE_ATT = False\n",
    "\n",
    "cfg = TRMConfig(\n",
    "    input_vocab_size=INPUT_TOKENS,\n",
    "    output_vocab_size=OUTPUT_TOKENS,\n",
    "    seq_len=SEQ_LEN,\n",
    "    d_model=D_MODEL,\n",
    "    n_layers=2,\n",
    "    use_attention=USE_ATT,\n",
    "    n_heads=8,\n",
    "    dropout=0.0,\n",
    "    mlp_ratio=4.0,\n",
    "    token_mlp_ratio=2.0,\n",
    "    n=N,\n",
    "    T=T,\n",
    "    k_last_ops=None,\n",
    "    stabilize_input_sums=True\n",
    ")\n",
    "\n",
    "model = TRM(cfg).to(device)\n",
    "print(\"Params (M):\", sum(p.numel() for p in model.parameters())/1e6)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=3e-4, weight_decay=0.0, betas=(0.9, 0.95)\n",
    ")\n",
    "\n",
    "scaler = make_grad_scaler(device.type == \"cuda\")\n",
    "ema = EMA(model, decay=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa8b8f5",
   "metadata": {},
   "source": [
    "## 5. Sanity Checks on Data\n",
    "Run assertions to verify input and label ranges for the Sudoku dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d8cf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity OK: x in [0,SIDE], y in [0,SIDE-1]\n"
     ]
    }
   ],
   "source": [
    "bx, by = next(iter(train_loader))\n",
    "assert bx.min().item() >= 0 and bx.max().item() <= SIDE\n",
    "assert by.min().item() >= 0 and by.max().item() < SIDE\n",
    "print(\"Sanity OK: x in [0,SIDE], y in [0,SIDE-1]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03144a",
   "metadata": {},
   "source": [
    "## 6. Training and Evaluation Functions\n",
    "Define training and evaluation functions, including loss calculation, metric reporting, and EMA evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46882911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match_from_logits(logits: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    preds = logits.argmax(dim=-1)\n",
    "    return (preds == y_true).all(dim=1).float()\n",
    "\n",
    "def token_ce_loss(logits: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    B, L, V = logits.shape\n",
    "    return F.cross_entropy(logits.reshape(B*L, V), y_true.reshape(B*L))\n",
    "\n",
    "def train_one_epoch(\n",
    "    model: TRM,\n",
    "    loader: DataLoader,\n",
    "    optimizer,\n",
    "    scaler,\n",
    "    epoch: int,\n",
    "    use_amp: bool = True,\n",
    "    ema: \"EMA | None\" = None\n",
    "):\n",
    "    model.train()\n",
    "    total_ce, total_halt, total_em, total_steps = 0.0, 0.0, 0.0, 0\n",
    "    for x_tokens, y_true in loader:\n",
    "        x_tokens = x_tokens.to(device, non_blocking=True)\n",
    "        y_true   = y_true.to(device,   non_blocking=True)\n",
    "        y_state, z_state = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "        for _ in range(N_SUP):\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            y_state, z_state, logits, halt_logit = model.forward_step(\n",
    "                x_tokens, y=y_state, z=z_state, n=N, T=T, k_last_ops=None\n",
    "            )\n",
    "            loss_ce = F.cross_entropy(logits.float().reshape(-1, OUTPUT_TOKENS), y_true.reshape(-1))\n",
    "            with torch.no_grad():\n",
    "                em = exact_match_from_logits(logits, y_true)\n",
    "            loss_halt = F.binary_cross_entropy_with_logits(halt_logit.float(), em)\n",
    "            loss = loss_ce + loss_halt\n",
    "            if use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                if ema is not None:\n",
    "                    ema.update(model)\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                if ema is not None:\n",
    "                    ema.update(model)\n",
    "            total_ce   += loss_ce.detach().item()\n",
    "            total_halt += loss_halt.detach().item()\n",
    "            total_em   += em.mean().item()\n",
    "            total_steps += 1\n",
    "    print(f\"Epoch {epoch:02d} | CE {total_ce/max(1,total_steps):.4f} | HaltBCE {total_halt/max(1,total_steps):.4f} | Exact-match {total_em/max(1,total_steps):.3f}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: TRM, loader: DataLoader, n_sup_eval: int = N_SUP):\n",
    "    model.eval()\n",
    "    em_list, cell_acc_list = [], []\n",
    "    for x_tokens, y_true in loader:\n",
    "        x_tokens = x_tokens.to(device)\n",
    "        y_true   = y_true.to(device)\n",
    "        y_state, z_state = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "        for _ in range(n_sup_eval):\n",
    "            y_state, z_state, logits, halt_logit = model.forward_step(\n",
    "                x_tokens, y=y_state, z=z_state, n=N, T=T, k_last_ops=None\n",
    "            )\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        em = (preds == y_true).all(dim=1).float()\n",
    "        cell_acc = (preds == y_true).float().mean(dim=1)\n",
    "        em_list.append(em); cell_acc_list.append(cell_acc)\n",
    "    em = torch.cat(em_list).mean().item()\n",
    "    cell_acc = torch.cat(cell_acc_list).mean().item()\n",
    "    print(f\"Validation | Exact-match {em:.3f} | Cell accuracy {cell_acc:.3f}\")\n",
    "    return em, cell_acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_with_ema(model: TRM, ema: EMA, loader: DataLoader, n_sup_eval: int = N_SUP):\n",
    "    with use_ema_weights(model, ema):\n",
    "        return evaluate(model, loader, n_sup_eval=n_sup_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d249ed8",
   "metadata": {},
   "source": [
    "## 7. Single Batch Forward and Training Step Check\n",
    "Perform a forward-only check and a single training step to verify model and gradient finiteness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a58bdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward-only finiteness: y1 True z1 True logits True halt_logit True\n",
      "Pre-backward finiteness: loss True loss_ce True loss_halt True\n",
      "Gradients finite: True\n",
      "Gradients finite: True\n",
      "Post-step forward finiteness: y2 True z2 True logits2 True halt2 True\n",
      "Post-step forward finiteness: y2 True z2 True logits2 True halt2 True\n"
     ]
    }
   ],
   "source": [
    "x_tokens, y_true = next(iter(train_loader))\n",
    "x_tokens = x_tokens.to(device)\n",
    "y_true   = y_true.to(device)\n",
    "\n",
    "# forward-only check (no training, no AMP)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y0, z0 = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "    y1, z1, logits, halt_logit = model.forward_step(x_tokens, y=y0, z=z0, n=N, T=T, k_last_ops=None)\n",
    "print(\"Forward-only finiteness:\",\n",
    "      \"y1\", torch.isfinite(y1).all().item(),\n",
    "      \"z1\", torch.isfinite(z1).all().item(),\n",
    "      \"logits\", torch.isfinite(logits).all().item(),\n",
    "      \"halt_logit\", torch.isfinite(halt_logit).all().item())\n",
    "\n",
    "# single training step in full FP32 (no AMP, tiny LR, no weight decay)\n",
    "model.train()\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.0)\n",
    "opt.zero_grad(set_to_none=True)\n",
    "y0, z0 = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "y1, z1, logits, halt_logit = model.forward_step(x_tokens, y=y0, z=z0, n=N, T=T, k_last_ops=None)\n",
    "loss_ce = F.cross_entropy(logits.float().reshape(-1, OUTPUT_TOKENS), y_true.reshape(-1))\n",
    "em = (logits.argmax(dim=-1) == y_true).all(dim=1).float()\n",
    "loss_halt = F.binary_cross_entropy_with_logits(halt_logit.float(), em)\n",
    "loss = loss_ce + loss_halt\n",
    "print(\"Pre-backward finiteness:\",\n",
    "      \"loss\", torch.isfinite(loss).item(),\n",
    "      \"loss_ce\", torch.isfinite(loss_ce).item(),\n",
    "      \"loss_halt\", torch.isfinite(loss_halt).item())\n",
    "loss.backward()\n",
    "all_grads_finite = True\n",
    "for n, p in model.named_parameters():\n",
    "    if p.grad is None:\n",
    "        continue\n",
    "    if not torch.isfinite(p.grad).all():\n",
    "        print(\"Non-finite grad in:\", n)\n",
    "        all_grads_finite = False\n",
    "        break\n",
    "print(\"Gradients finite:\", all_grads_finite)\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "opt.step()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y0, z0 = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "    y2, z2, logits2, halt2 = model.forward_step(x_tokens, y=y0, z=z0, n=N, T=T, k_last_ops=None)\n",
    "print(\"Post-step forward finiteness:\",\n",
    "      \"y2\", torch.isfinite(y2).all().item(),\n",
    "      \"z2\", torch.isfinite(z2).all().item(),\n",
    "      \"logits2\", torch.isfinite(logits2).all().item(),\n",
    "      \"halt2\", torch.isfinite(halt2).all().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbc352e",
   "metadata": {},
   "source": [
    "## 8. Training Loop\n",
    "Run the main training loop for several epochs, reporting metrics for both raw and EMA weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "364a85ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | CE 0.4201 | HaltBCE 0.3554 | Exact-match 0.218\n",
      "Validation | Exact-match 0.373 | Cell accuracy 0.902\n",
      "Validation | Exact-match 0.373 | Cell accuracy 0.902\n",
      "Validation | Exact-match 0.209 | Cell accuracy 0.874\n",
      "Validation (raw) | EM 0.373 | Cell 0.902\n",
      "Validation (EMA) | EM 0.209 | Cell 0.874\n",
      "Validation | Exact-match 0.209 | Cell accuracy 0.874\n",
      "Validation (raw) | EM 0.373 | Cell 0.902\n",
      "Validation (EMA) | EM 0.209 | Cell 0.874\n",
      "Epoch 02 | CE 0.2328 | HaltBCE 0.4928 | Exact-match 0.477\n",
      "Epoch 02 | CE 0.2328 | HaltBCE 0.4928 | Exact-match 0.477\n",
      "Validation | Exact-match 0.473 | Cell accuracy 0.918\n",
      "Validation | Exact-match 0.473 | Cell accuracy 0.918\n",
      "Validation | Exact-match 0.543 | Cell accuracy 0.930\n",
      "Validation (raw) | EM 0.473 | Cell 0.918\n",
      "Validation (EMA) | EM 0.543 | Cell 0.930\n",
      "Node accuracy history: [0.90234375, 0.918212890625]\n",
      "Validation | Exact-match 0.543 | Cell accuracy 0.930\n",
      "Validation (raw) | EM 0.473 | Cell 0.918\n",
      "Validation (EMA) | EM 0.543 | Cell 0.930\n",
      "Node accuracy history: [0.90234375, 0.918212890625]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "node_acc_history = []\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_one_epoch(model, train_loader, optimizer, scaler, epoch, use_amp=False, ema=ema)\n",
    "    em_raw, cell_raw = evaluate(model, val_loader, n_sup_eval=N_SUP)\n",
    "    em_ema, cell_ema = evaluate_with_ema(model, ema, val_loader)\n",
    "    node_acc_history.append(cell_raw)\n",
    "    print(f\"Validation (raw) | EM {em_raw:.3f} | Cell {cell_raw:.3f}\")\n",
    "    print(f\"Validation (EMA) | EM {em_ema:.3f} | Cell {cell_ema:.3f}\")\n",
    "print(\"Node accuracy history:\", node_acc_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cf044",
   "metadata": {},
   "source": [
    "## 9. Model Inference and Visualization\n",
    "Implement a function to solve and display Sudoku puzzles using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b19783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Puzzle 0:\n",
      "[[3 0 1 0]\n",
      " [0 0 0 2]\n",
      " [0 1 2 3]\n",
      " [2 0 0 1]]\n",
      "Pred:\n",
      "[[3 2 1 4]\n",
      " [1 2 3 2]\n",
      " [4 1 2 3]\n",
      " [2 3 4 1]]\n",
      "True:\n",
      "[[3 2 1 4]\n",
      " [1 4 3 2]\n",
      " [4 1 2 3]\n",
      " [2 3 4 1]]\n",
      "\n",
      "Puzzle 1:\n",
      "[[0 0 0 4]\n",
      " [4 0 3 1]\n",
      " [0 4 1 3]\n",
      " [0 1 4 2]]\n",
      "Pred:\n",
      "[[1 3 2 4]\n",
      " [4 2 3 1]\n",
      " [2 4 1 3]\n",
      " [3 1 4 2]]\n",
      "True:\n",
      "[[1 3 2 4]\n",
      " [4 2 3 1]\n",
      " [2 4 1 3]\n",
      " [3 1 4 2]]\n",
      "\n",
      "Puzzle 2:\n",
      "[[0 4 0 1]\n",
      " [0 0 3 4]\n",
      " [0 2 4 3]\n",
      " [4 3 1 0]]\n",
      "Pred:\n",
      "[[3 4 2 1]\n",
      " [2 1 3 4]\n",
      " [1 2 4 3]\n",
      " [4 3 1 2]]\n",
      "True:\n",
      "[[3 4 2 1]\n",
      " [2 1 3 4]\n",
      " [1 2 4 3]\n",
      " [4 3 1 2]]\n",
      "\n",
      "Puzzle 3:\n",
      "[[0 0 4 2]\n",
      " [0 4 3 1]\n",
      " [4 0 1 3]\n",
      " [3 0 0 4]]\n",
      "Pred:\n",
      "[[1 3 4 2]\n",
      " [2 4 3 1]\n",
      " [4 2 1 3]\n",
      " [3 2 2 4]]\n",
      "True:\n",
      "[[1 3 4 2]\n",
      " [2 4 3 1]\n",
      " [4 2 1 3]\n",
      " [3 1 2 4]]\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def solve_and_show(model: TRM, loader: DataLoader, n_batches: int = 1):\n",
    "    model.eval()\n",
    "    shown = 0\n",
    "    for x_tokens, y_true in loader:\n",
    "        x_tokens = x_tokens.to(device)\n",
    "        y_true   = y_true.to(device)\n",
    "        y_state, z_state = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "        for _ in range(N_SUP):\n",
    "            y_state, z_state, logits, halt_logit = model.forward_step(\n",
    "                x_tokens, y=y_state, z=z_state, n=N, T=T, k_last_ops=None\n",
    "            )\n",
    "        preds_tok = logits.argmax(dim=-1).cpu().numpy()\n",
    "        xs = x_tokens.cpu().numpy()\n",
    "        ys_tok = y_true.cpu().numpy()\n",
    "        for i in range(min(4, xs.shape[0])):\n",
    "            print(f\"\\nPuzzle {shown+i}:\")\n",
    "            print(xs[i].reshape(4,4))\n",
    "            print(\"Pred:\")\n",
    "            print((preds_tok[i] + 1).reshape(4,4))   # tokens -> digits\n",
    "            print(\"True:\")\n",
    "            print((ys_tok[i] + 1).reshape(4,4))\n",
    "        shown += 1\n",
    "        if shown >= n_batches:\n",
    "            break\n",
    "\n",
    "solve_and_show(model, val_loader, n_batches=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c80de8",
   "metadata": {},
   "source": [
    "## 10. Forward Finiteness Probe\n",
    "Probe the model for non-finite values during forward passes to ensure numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5229c65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward finiteness probe passed.\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def forward_finiteness_probe(model: TRM, x_tokens: torch.Tensor):\n",
    "    model.eval()\n",
    "    y, z = model.init_state(batch_size=x_tokens.size(0), device=x_tokens.device)\n",
    "    x_h = model.embed_input(x_tokens)\n",
    "    def check(tag, t):\n",
    "        if not torch.isfinite(t).all():\n",
    "            raise RuntimeError(f\"Non-finite values detected at {tag}\")\n",
    "    for t in range(T):\n",
    "        for i in range(N):\n",
    "            h_z = (x_h + y + z) if not model.cfg.stabilize_input_sums else (x_h + y + z) / math.sqrt(3.0)\n",
    "            check(f\"T{t}-hz{i}\", h_z)\n",
    "            z = model._net(h_z)\n",
    "            check(f\"T{t}-z{i}\", z)\n",
    "        h_y = (y + z) if not model.cfg.stabilize_input_sums else (y + z) / math.sqrt(2.0)\n",
    "        check(f\"T{t}-hy\", h_y)\n",
    "        y = model._net(h_y)\n",
    "        check(f\"T{t}-y\", y)\n",
    "    logits = model.output_head(y)\n",
    "    halt_logit = model.halt_head(y)\n",
    "    check(\"logits\", logits)\n",
    "    check(\"halt_logit\", halt_logit)\n",
    "    print(\"Forward finiteness probe passed.\")\n",
    "\n",
    "x_tokens, _ = next(iter(train_loader))\n",
    "forward_finiteness_probe(model, x_tokens.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5145761d",
   "metadata": {},
   "source": [
    "## 11. Embedding and Input Checks\n",
    "Check input token ranges, embedding matrix finiteness, and embedding lookup results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f16cdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_tokens range: 0 4 torch.int64\n",
      "embedding finite? True max|w|: 3.2094664573669434\n",
      "x_h finite? True\n"
     ]
    }
   ],
   "source": [
    "x_tokens, _ = next(iter(train_loader))\n",
    "x_tokens = x_tokens.to(device)\n",
    "print(\"x_tokens range:\", int(x_tokens.min()), int(x_tokens.max()), x_tokens.dtype)\n",
    "w = model.input_emb.weight.data\n",
    "print(\"embedding finite?\", torch.isfinite(w).all().item(), \"max|w|:\", float(w.abs().max()))\n",
    "x_h = model.embed_input(x_tokens)\n",
    "print(\"x_h finite?\", torch.isfinite(x_h).all().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c59ea8",
   "metadata": {},
   "source": [
    "## Appendix: Graph Coloring Puzzle Dataset\n",
    "Example: Generating synthetic graph coloring puzzles for neural network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2feddc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency shape: torch.Size([8, 36])\n",
      "Color labels shape: torch.Size([8, 6])\n"
     ]
    }
   ],
   "source": [
    "class GraphColoringDataset(GameDataset):\n",
    "    \"\"\"Synthetic undirected graph coloring puzzles.\"\"\"\n",
    "    def __init__(self, n_samples: int, n_nodes: int = 6, n_colors: int = 3, edge_prob: float = 0.4, seed: int = 0):\n",
    "        self.n_nodes = n_nodes\n",
    "        self.n_colors = n_colors\n",
    "        self.edge_prob = edge_prob\n",
    "        super().__init__(n_samples, seed)\n",
    "    def _generate_sample(self):\n",
    "        # Generate random adjacency matrix (undirected, no self-loops)\n",
    "        adj = np.triu((np.random.rand(self.n_nodes, self.n_nodes) < self.edge_prob).astype(np.int64), 1)\n",
    "        adj = adj + adj.T\n",
    "        # Generate a valid coloring (greedy, not always optimal)\n",
    "        colors = np.full(self.n_nodes, -1, dtype=np.int64)\n",
    "        for node in range(self.n_nodes):\n",
    "            forbidden = set(colors[adj[node] == 1])\n",
    "            for c in range(self.n_colors):\n",
    "                if c not in forbidden:\n",
    "                    colors[node] = c\n",
    "                    break\n",
    "        # Input: adjacency matrix flattened, Output: node colors\n",
    "        x_tokens = adj.flatten()\n",
    "        y_tokens = colors\n",
    "        return torch.from_numpy(x_tokens), torch.from_numpy(y_tokens)\n",
    "\n",
    "# Example usage:\n",
    "gc_dataset = GraphColoringDataset(n_samples=100, n_nodes=6, n_colors=3, edge_prob=0.4, seed=42)\n",
    "gc_loader = DataLoader(gc_dataset, batch_size=8, shuffle=True)\n",
    "x_gc, y_gc = next(iter(gc_loader))\n",
    "print(\"Adjacency shape:\", x_gc.shape)\n",
    "print(\"Color labels shape:\", y_gc.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
