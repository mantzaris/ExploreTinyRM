{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21821942",
   "metadata": {},
   "source": [
    "# Modular TRM Training for Traveling Salesman Problem (TSP)\n",
    "\n",
    "This notebook demonstrates a modular approach to training and evaluating a TRM neural network on synthetic TSP instances using PyTorch. The code is organized for easy adaptation to other combinatorial optimization problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c67f22f",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Set Up Environment\n",
    "Import all required libraries, set random seeds, and configure device (CPU/GPU) for TSP experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f07034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os, math, random\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Any, List\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "sys.path.append(os.path.join(\"..\", \"src\"))\n",
    "from exploretinyrm.trm import TRM, TRMConfig\n",
    "\n",
    "def set_seed(seed: int = 123):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(123)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee9c01d",
   "metadata": {},
   "source": [
    "## 2. AMP and EMA Utilities\n",
    "Define automatic mixed precision (AMP) and exponential moving average (EMA) utility functions and classes for training stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a865ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torch.amp import autocast as _autocast, GradScaler as _GradScaler\n",
    "    _USE_TORCH_AMP = True\n",
    "except ImportError:\n",
    "    from torch.cuda.amp import autocast as _autocast, GradScaler as _GradScaler\n",
    "    _USE_TORCH_AMP = False\n",
    "\n",
    "def make_grad_scaler(is_cuda: bool):\n",
    "    if _USE_TORCH_AMP:\n",
    "        try:\n",
    "            return _GradScaler(\"cuda\", enabled=is_cuda)\n",
    "        except TypeError:\n",
    "            return _GradScaler(enabled=is_cuda)\n",
    "    else:\n",
    "        return _GradScaler(enabled=is_cuda)\n",
    "\n",
    "def amp_autocast(is_cuda: bool, use_amp: bool):\n",
    "    if _USE_TORCH_AMP:\n",
    "        try:\n",
    "            return _autocast(device_type=\"cuda\", enabled=(is_cuda and use_amp))\n",
    "        except TypeError:\n",
    "            return _autocast(enabled=(is_cuda and use_amp))\n",
    "    else:\n",
    "        return _autocast(enabled=(is_cuda and use_amp))\n",
    "\n",
    "class EMA:\n",
    "    def __init__(self, model: torch.nn.Module, decay: float = 0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {\n",
    "            name: param.detach().clone()\n",
    "            for name, param in model.named_parameters()\n",
    "            if param.requires_grad\n",
    "        }\n",
    "\n",
    "    def update(self, model: torch.nn.Module) -> None:\n",
    "        d = self.decay\n",
    "        with torch.no_grad():\n",
    "            for name, param in model.named_parameters():\n",
    "                if not param.requires_grad:\n",
    "                    continue\n",
    "                self.shadow[name].mul_(d).add_(param.detach(), alpha=1.0 - d)\n",
    "\n",
    "    def copy_to(self, model: torch.nn.Module) -> None:\n",
    "        with torch.no_grad():\n",
    "            for name, param in model.named_parameters():\n",
    "                if name in self.shadow:\n",
    "                    param.copy_(self.shadow[name])\n",
    "\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def use_ema_weights(model: torch.nn.Module, ema: EMA):\n",
    "    backup = {\n",
    "        name: param.detach().clone()\n",
    "        for name, param in model.named_parameters()\n",
    "        if param.requires_grad\n",
    "    }\n",
    "    ema.copy_to(model)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        with torch.no_grad():\n",
    "            for name, param in model.named_parameters():\n",
    "                if name in backup:\n",
    "                    param.copy_(backup[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f650707a",
   "metadata": {},
   "source": [
    "## 3. TSP Dataset Preparation\n",
    "Implement dataset generation for synthetic TSP instances, including random city coordinates and optimal tour labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72085f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSPDataset(Dataset):\n",
    "    \"\"\"Synthetic TSP instances: random city coordinates and optimal tour labels.\"\"\"\n",
    "    def __init__(self, n_samples: int, n_cities: int = 5, seed: int = 0):\n",
    "        self.n_cities = n_cities\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.samples = [self._generate_sample() for _ in range(n_samples)]\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx): return self.samples[idx]\n",
    "    def _generate_sample(self):\n",
    "        coords = self.rng.uniform(0, 1, (self.n_cities, 2))\n",
    "        # Compute distance matrix\n",
    "        dist = np.linalg.norm(coords[:, None, :] - coords[None, :, :], axis=-1)\n",
    "        # Find optimal tour (brute-force for small n_cities)\n",
    "        from itertools import permutations\n",
    "        best_tour = None\n",
    "        best_length = float('inf')\n",
    "        for perm in permutations(range(self.n_cities)):\n",
    "            length = sum(dist[perm[i], perm[(i+1)%self.n_cities]] for i in range(self.n_cities))\n",
    "            if length < best_length:\n",
    "                best_length = length\n",
    "                best_tour = perm\n",
    "        x_tokens = coords.flatten() # [n_cities*2]\n",
    "        y_tokens = np.array(best_tour, dtype=np.int64) # [n_cities]\n",
    "        return torch.from_numpy(x_tokens).float(), torch.from_numpy(y_tokens)\n",
    "\n",
    "def get_tsp_loaders(n_train=512, n_val=128, batch_size=16, n_cities=5, seed=123):\n",
    "    ds_tr = TSPDataset(n_train, n_cities=n_cities, seed=seed)\n",
    "    ds_va = TSPDataset(n_val, n_cities=n_cities, seed=seed+1)\n",
    "    return (\n",
    "        DataLoader(ds_tr, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True),\n",
    "        DataLoader(ds_va, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    )\n",
    "\n",
    "train_loader, val_loader = get_tsp_loaders(\n",
    "    n_train=2048,\n",
    "    n_val=512,\n",
    "    batch_size=16,\n",
    "    n_cities=5,\n",
    "    seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef0f2ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "City coordinates: [[0.6823519  0.05382102]\n",
      " [0.22035988 0.18437181]\n",
      " [0.1759059  0.8120945 ]\n",
      " [0.92334497 0.2765744 ]\n",
      " [0.81975454 0.8898927 ]]\n",
      "Optimal tour: [0 3 4 2 1]\n",
      "Example 1:\n",
      "City coordinates: [[0.51297045 0.2449646 ]\n",
      " [0.8242416  0.21376297]\n",
      " [0.74146706 0.6299402 ]\n",
      " [0.92740726 0.23190819]\n",
      " [0.79912513 0.51816505]]\n",
      "Optimal tour: [0 1 3 4 2]\n"
     ]
    }
   ],
   "source": [
    "# Show some examples of the dataset\n",
    "for i in range(2):\n",
    "    x, y = train_loader.dataset[i]\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"City coordinates:\", x.numpy().reshape(-1, 2))\n",
    "    print(\"Optimal tour:\", y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d06965",
   "metadata": {},
   "source": [
    "## 4. Model Configuration and Initialization\n",
    "Configure TRM model parameters for TSP, instantiate the model, optimizer, scaler, and EMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d65799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params (M): 0.523552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhopw\\miniconda3\\envs\\torch121\\Lib\\site-packages\\torch\\cuda\\__init__.py:235: UserWarning: \n",
      "NVIDIA GeForce RTX 5060 Ti with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90 sm_37 compute_37.\n",
      "If you want to use the NVIDIA GeForce RTX 5060 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "N_CITIES = 5\n",
    "INPUT_TOKENS = 1000  # Discretized coordinate values (for embedding)\n",
    "OUTPUT_TOKENS = N_CITIES  # City indices: 0..N_CITIES-1\n",
    "SEQ_LEN = N_CITIES * 2  # Each city has (x, y)\n",
    "\n",
    "D_MODEL = 128\n",
    "N_SUP   = 16\n",
    "N       = 6\n",
    "T       = 3\n",
    "USE_ATT = False\n",
    "\n",
    "cfg = TRMConfig(\n",
    "    input_vocab_size=INPUT_TOKENS,\n",
    "    output_vocab_size=OUTPUT_TOKENS,\n",
    "    seq_len=SEQ_LEN,\n",
    "    d_model=D_MODEL,\n",
    "    n_layers=2,\n",
    "    use_attention=USE_ATT,\n",
    "    n_heads=8,\n",
    "    dropout=0.0,\n",
    "    mlp_ratio=4.0,\n",
    "    token_mlp_ratio=2.0,\n",
    "    n=N,\n",
    "    T=T,\n",
    "    k_last_ops=None,\n",
    "    stabilize_input_sums=True\n",
    ")\n",
    "\n",
    "model = TRM(cfg).to(device)\n",
    "print(\"Params (M):\", sum(p.numel() for p in model.parameters())/1e6)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=3e-4, weight_decay=0.0, betas=(0.9, 0.95)\n",
    ")\n",
    "\n",
    "scaler = make_grad_scaler(device.type == \"cuda\")\n",
    "ema = EMA(model, decay=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed125836",
   "metadata": {},
   "source": [
    "## 5. Sanity Checks on Data\n",
    "Run assertions to verify input shapes, value ranges, and tour validity for the TSP dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d70fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity OK: coordinates in [0,1], valid tour.\n"
     ]
    }
   ],
   "source": [
    "# Sanity checks for TSP data\n",
    "for i in range(len(train_loader.dataset)):\n",
    "    x, y = train_loader.dataset[i]\n",
    "    coords = x.numpy().reshape(N_CITIES, 2)\n",
    "    assert coords.shape == (N_CITIES, 2)\n",
    "    assert np.all((coords >= 0) & (coords <= 1))\n",
    "    assert y.shape[0] == N_CITIES\n",
    "    assert set(y.numpy()) == set(range(N_CITIES)), \"Tour must visit each city exactly once\"\n",
    "print(\"Sanity OK: coordinates in [0,1], valid tour.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107e0c58",
   "metadata": {},
   "source": [
    "## 6. Training and Evaluation Functions\n",
    "Define training and evaluation functions, including loss calculation, metric reporting, and EMA evaluation for TSP tours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ece5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tour_ce_loss(logits: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    # logits: [B, N, C], y_true: [B, N]\n",
    "    B, N, C = logits.shape\n",
    "    return F.cross_entropy(logits.reshape(B*N, C), y_true.reshape(B*N))\n",
    "\n",
    "def tour_exact_match(preds, y_true):\n",
    "    # Returns fraction of cities in correct position\n",
    "    preds = preds.cpu().numpy() if isinstance(preds, torch.Tensor) else preds\n",
    "    y_true = y_true.cpu().numpy() if isinstance(y_true, torch.Tensor) else y_true\n",
    "    return np.mean(preds == y_true)\n",
    "\n",
    "def train_one_epoch(\n",
    "    model: TRM,\n",
    "    loader: DataLoader,\n",
    "    optimizer,\n",
    "    scaler,\n",
    "    epoch: int,\n",
    "    use_amp: bool = True,\n",
    "    ema: \"EMA | None\" = None\n",
    "):\n",
    "    model.train()\n",
    "    total_ce, total_em, total_steps = 0.0, 0.0, 0\n",
    "    for x_tokens, y_true in loader:\n",
    "        x_tokens = x_tokens.to(device, non_blocking=True)\n",
    "        y_true   = y_true.to(device,   non_blocking=True)\n",
    "        y_state, z_state = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "        for _ in range(N_SUP):\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            y_state, z_state, logits, halt_logit = model.forward_step(\n",
    "                x_tokens, y=y_state, z=z_state, n=N, T=T, k_last_ops=None\n",
    "            )\n",
    "            logits_tour = logits.float().view(logits.size(0), N_CITIES, logits.size(2))\n",
    "            loss_ce = tour_ce_loss(logits_tour, y_true)\n",
    "            with torch.no_grad():\n",
    "                em = torch.tensor([tour_exact_match(logits_tour[i].argmax(dim=-1), y_true[i]) for i in range(x_tokens.size(0))], device=logits.device)\n",
    "            loss = loss_ce\n",
    "            if use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                if ema is not None:\n",
    "                    ema.update(model)\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                if ema is not None:\n",
    "                    ema.update(model)\n",
    "            total_ce   += loss_ce.detach().item()\n",
    "            total_em   += em.mean().item()\n",
    "            total_steps += 1\n",
    "    print(f\"Epoch {epoch:02d} | CE {total_ce/max(1,total_steps):.4f} | Exact match {total_em/max(1,total_steps):.3f}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: TRM, loader: DataLoader, n_sup_eval: int = N_SUP, show_examples: int = 3):\n",
    "    model.eval()\n",
    "    acc_list = []\n",
    "    example_count = 0\n",
    "    for x_tokens, y_true in loader:\n",
    "        x_tokens = x_tokens.to(device)\n",
    "        y_true   = y_true.to(device)\n",
    "        y_state, z_state = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "        for _ in range(n_sup_eval):\n",
    "            y_state, z_state, logits, halt_logit = model.forward_step(\n",
    "                x_tokens, y=y_state, z=z_state, n=N, T=T, k_last_ops=None\n",
    "            )\n",
    "        logits_tour = logits.float().view(logits.size(0), N_CITIES, logits.size(2))\n",
    "        em = torch.tensor([tour_exact_match(logits_tour[i].argmax(dim=-1), y_true[i]) for i in range(x_tokens.size(0))], device=logits.device)\n",
    "        acc = em.mean()\n",
    "        acc_list.append(acc)\n",
    "        # Print a few examples from the first batch\n",
    "        if example_count < show_examples:\n",
    "            preds = logits_tour.argmax(dim=-1)\n",
    "            xs = x_tokens.cpu().numpy()\n",
    "            ys = y_true.cpu().numpy()\n",
    "            preds_np = preds.cpu().numpy()\n",
    "            for i in range(min(show_examples - example_count, xs.shape[0])):\n",
    "                print(f\"\\nExample {example_count + 1}:\")\n",
    "                print(\"City coordinates:\")\n",
    "                print(xs[i].reshape(N_CITIES, 2))\n",
    "                print(\"Predicted tour:\", preds_np[i])\n",
    "                print(\"True tour:\", ys[i])\n",
    "                print(\"Exact match score:\", tour_exact_match(preds_np[i], ys[i]))\n",
    "                example_count += 1\n",
    "    acc = torch.stack(acc_list).mean().item()\n",
    "    print(f\"Validation | Exact match {acc:.3f}\")\n",
    "    return acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_with_ema(model: TRM, ema: EMA, loader: DataLoader, n_sup_eval: int = N_SUP):\n",
    "    with use_ema_weights(model, ema):\n",
    "        return evaluate(model, loader, n_sup_eval=n_sup_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea77e5e",
   "metadata": {},
   "source": [
    "## 7. Training Loop\n",
    "Run the main training loop for several epochs, reporting metrics for both raw and EMA weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d70cdd29",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m EPOCHS = \u001b[32m5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, EPOCHS+\u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     acc_raw = evaluate(model, val_loader)\n\u001b[32m      5\u001b[39m     acc_ema = evaluate_with_ema(model, ema, val_loader)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, loader, optimizer, scaler, epoch, use_amp, ema)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_SUP):\n\u001b[32m     28\u001b[39m     optimizer.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     y_state, z_state, logits, halt_logit = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mz_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m=\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_last_ops\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     logits_tour = logits.float().view(logits.size(\u001b[32m0\u001b[39m), N_CITIES, logits.size(\u001b[32m2\u001b[39m))\n\u001b[32m     33\u001b[39m     loss_ce = tour_ce_loss(logits_tour, y_true)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mhopw\\Documents\\Work\\HRM\\ExploreTinyRM\\Alex\\..\\src\\exploretinyrm\\trm.py:434\u001b[39m, in \u001b[36mTRM.forward_step\u001b[39m\u001b[34m(self, x_tokens, y, z, n, T, k_last_ops)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward_step\u001b[39m(\n\u001b[32m    419\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    420\u001b[39m     x_tokens: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    426\u001b[39m     k_last_ops: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    427\u001b[39m ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n\u001b[32m    428\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    429\u001b[39m \u001b[33;03m    One supervision step (described in 4.1 and illustrated in Figure 1 of the paper):\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[33;03m      1 x = embed(x_tokens)\u001b[39;00m\n\u001b[32m    431\u001b[39m \u001b[33;03m      2 run T deep-recursions (T-1 no_grad, 1 with grad)\u001b[39;00m\n\u001b[32m    432\u001b[39m \u001b[33;03m      3 return next (y, z) to carry across steps, plus logits and halt_logit\u001b[39;00m\n\u001b[32m    433\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m     x_h = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (z \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    436\u001b[39m         y, z = \u001b[38;5;28mself\u001b[39m.init_state(batch_size=x_tokens.size(\u001b[32m0\u001b[39m), device=x_tokens.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mhopw\\Documents\\Work\\HRM\\ExploreTinyRM\\Alex\\..\\src\\exploretinyrm\\trm.py:416\u001b[39m, in \u001b[36mTRM.embed_input\u001b[39m\u001b[34m(self, x_tokens)\u001b[39m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_tokens: torch.Tensor) -> torch.Tensor:\n\u001b[32m    412\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[33;03m    Embed tokenized input x: [B, L] -> [B, L, D]\u001b[39;00m\n\u001b[32m    414\u001b[39m \u001b[33;03m    already have x in hidden space, bypass and feed it directly to deep_recursion)\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mhopw\\miniconda3\\envs\\torch121\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mhopw\\miniconda3\\envs\\torch121\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mhopw\\miniconda3\\envs\\torch121\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mhopw\\miniconda3\\envs\\torch121\\Lib\\site-packages\\torch\\nn\\functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_one_epoch(model, train_loader, optimizer, scaler, epoch, use_amp=False, ema=ema)\n",
    "    acc_raw = evaluate(model, val_loader)\n",
    "    acc_ema = evaluate_with_ema(model, ema, val_loader)\n",
    "    print(f\"Validation (raw) | Tour accuracy {acc_raw:.3f}\")\n",
    "    print(f\"Validation (EMA) | Tour accuracy {acc_ema:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95266051",
   "metadata": {},
   "source": [
    "## 8. Model Inference and Visualization\n",
    "Show predicted tours for a batch of TSP instances and compare to true optimal tours, including graphical visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "@torch.no_grad()\n",
    "def show_predictions(model: TRM, loader: DataLoader, n_batches: int = 1):\n",
    "    model.eval()\n",
    "    shown = 0\n",
    "    for x_tokens, y_true in loader:\n",
    "        x_tokens = x_tokens.to(device)\n",
    "        y_true   = y_true.to(device)\n",
    "        y_state, z_state = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "        for _ in range(N_SUP):\n",
    "            y_state, z_state, logits, halt_logit = model.forward_step(\n",
    "                x_tokens, y=y_state, z=z_state, n=N, T=T, k_last_ops=None\n",
    "            )\n",
    "        logits_tour = logits.view(logits.size(0), N_CITIES, logits.size(2))\n",
    "        preds = logits_tour.argmax(dim=-1).cpu().numpy()\n",
    "        xs = x_tokens.cpu().numpy()\n",
    "        ys = y_true.cpu().numpy()\n",
    "        for i in range(min(4, xs.shape[0])):\n",
    "            coords = xs[i].reshape(N_CITIES, 2)\n",
    "            pred_tour = preds[i]\n",
    "            true_tour = ys[i]\n",
    "            plt.figure(figsize=(6,3))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.title(\"Predicted Tour\")\n",
    "            plt.plot(coords[pred_tour,0], coords[pred_tour,1], marker='o')\n",
    "            for j, (x, y) in enumerate(coords):\n",
    "                plt.text(x, y, str(j), fontsize=12)\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.title(\"True Tour\")\n",
    "            plt.plot(coords[true_tour,0], coords[true_tour,1], marker='o')\n",
    "            for j, (x, y) in enumerate(coords):\n",
    "                plt.text(x, y, str(j), fontsize=12)\n",
    "            plt.suptitle(f\"TSP Example {shown+i}\")\n",
    "            plt.show()\n",
    "        shown += 1\n",
    "        if shown >= n_batches:\n",
    "            break\n",
    "\n",
    "show_predictions(model, val_loader, n_batches=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
